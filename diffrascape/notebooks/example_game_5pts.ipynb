{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorforce.environments import Environment\n",
    "from tensorforce.agents import Agent\n",
    "from tensorforce.execution import Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main game"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(mean,var):\n",
    "    return mean+var*2.0*(np.random.random()-0.5)\n",
    "\n",
    "class CustomEnvironment(Environment):\n",
    "\n",
    "    def __init__(self, N=3, clist = [10., 10., 10.], vlist = [3.0,4.0,5.0], max_turns = 30, bad_list = [False,False,True]):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.clist = clist\n",
    "        self.vlist = vlist\n",
    "        self.max_turns = max_turns\n",
    "        self.turn = 0\n",
    "        self.picked_count = np.zeros(self.N)\n",
    "        self.measured_list = []\n",
    "        self.bad_list = bad_list\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def current_mean(self):\n",
    "\n",
    "        return [np.mean([el for el in sublist]) for sublist in self.measured_list]\n",
    "\n",
    "        #return mean_list\n",
    "    \n",
    "    def current_stddev(self):\n",
    "        return [np.var([el for el in sublist])**.5 for sublist in self.measured_list]\n",
    "\n",
    "    \n",
    "    def current_norm_stddev(self):\n",
    "        stddev_list = self.current_stddev()\n",
    "        return stddev_list / max(stddev_list)\n",
    "    \n",
    "    def states(self):\n",
    "        return dict(type='float', shape=(self.N*2,))\n",
    "\n",
    "    def actions(self):\n",
    "        return dict(type='int', num_values=self.N)\n",
    "\n",
    "    def reset(self):\n",
    "        #rshuffle the clist/vlist order, but don't change them.\n",
    "        z = list(zip(self.clist, self.vlist, self.bad_list))\n",
    "        np.random.shuffle(z)\n",
    "        self.clist, self.vlist, self.bad_list = zip(*z)\n",
    "        self.measured_list = []\n",
    "        self.turn = 0\n",
    "        \n",
    "        #take first measurments\n",
    "        for i in range(self.N):\n",
    "            this_list = []\n",
    "            for j in range(2):\n",
    "                this_list.append(get_val(mean=self.clist[i],var=self.vlist[i]))\n",
    "            self.measured_list.append(this_list)\n",
    "            \n",
    "        #state is the current variance of each point\n",
    "        self.state = np.zeros(2*self.N)\n",
    "        for i in range(self.N):\n",
    "            self.state[i] = np.var(self.measured_list[i])#**.5\n",
    "            self.state[int(self.N)+i] = self.picked_count[i]/float(self.max_turns)\n",
    "        \n",
    "        return self.state     \n",
    "    \n",
    "    def execute(self, actions):\n",
    "        #assert 0 <= actions.item() <= 3\n",
    "        \n",
    "        #take another measurement of value 'action'\n",
    "        this_val = get_val(mean=self.clist[actions],var=self.vlist[actions])\n",
    "        self.picked_count[int(actions)] += 1.0\n",
    "        self.measured_list[actions].append(this_val)\n",
    "        \n",
    "        next_state = self.state\n",
    "        next_state[actions] = np.var(self.measured_list[actions])#**.5\n",
    "        next_state[self.N+actions] = self.picked_count[(int(actions))] / self.max_turns\n",
    "\n",
    "        terminal = False\n",
    "        \n",
    "        reward = 0\n",
    "        self.turn += 1\n",
    "        if self.bad_list[actions]: #if this is a bad sample\n",
    "            reward += 1 #give 1 point\n",
    "\n",
    "        if self.turn >= self.max_turns:\n",
    "            terminal = True\n",
    "            reward = 0.0\n",
    "            #check if we've gotten min score on bad points\n",
    "            for i in range(self.N):\n",
    "                if self.bad_list[i] and self.picked_count[i] >= 20:\n",
    "                    reward += 100\n",
    "                    #print ('woohoo '+str(i))\n",
    "\n",
    "        return next_state, terminal, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Policies"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sequential_game(N,clist,vlist,bad_list,max_turns):\n",
    "    env = CustomEnvironment(N=N,\n",
    "            clist=clist,\n",
    "            vlist=vlist,\n",
    "            bad_list = bad_list,\n",
    "            max_turns=max_turns)\n",
    "\n",
    "    sum_points = 0\n",
    "    game_terminated = False\n",
    "\n",
    "    iguess = 0\n",
    "    while not game_terminated:\n",
    "        best_guess = int(iguess)\n",
    "        iguess += 1\n",
    "        next_state, game_terminated, next_reward = env.execute(iguess%env.N)\n",
    "        sum_points += next_reward\n",
    "    return sum_points\n",
    "\n",
    "def play_omniscent_game(N,clist,vlist,bad_list,max_turns):\n",
    "    env = CustomEnvironment(N=N,\n",
    "            clist=clist,\n",
    "            vlist=vlist,\n",
    "            bad_list = bad_list,\n",
    "            max_turns=max_turns)\n",
    "    \n",
    "    sum_points = 0\n",
    "    game_terminated = False\n",
    "\n",
    "    while not game_terminated:\n",
    "        omniscent_guess = np.argmax(abs(10. - np.array(env.current_mean())))\n",
    "        next_state, game_terminated, next_reward = env.execute(omniscent_guess)\n",
    "        sum_points += next_reward\n",
    "    return sum_points\n",
    "\n",
    "def play_exploring_game(N,clist,vlist,max_turns,bad_list,explore_frac=.1):\n",
    "    env = CustomEnvironment(N=N,\n",
    "            clist=clist,\n",
    "            vlist=vlist,\n",
    "            bad_list = bad_list,\n",
    "            max_turns=max_turns)\n",
    "\n",
    "    sum_points = 0\n",
    "    game_terminated = False\n",
    "\n",
    "    while not game_terminated:\n",
    "        best_guess = np.argmax(env.current_norm_stddev())\n",
    "        if np.random.random() < explore_frac:\n",
    "            best_guess = np.argmin(env.picked_count)\n",
    "        \n",
    "        next_state, game_terminated, next_reward = env.execute(best_guess)\n",
    "        sum_points += next_reward\n",
    "\n",
    "    return sum_points\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sequential score 68.0\nomniscent score 678.0\n"
    }
   ],
   "source": [
    "N = 30\n",
    "clist = 30*[10.0]\n",
    "vlist = np.ones(30)*0.2\n",
    "vlist[0:5] *= 20.0 #20 times higher variance in bad ones\n",
    "bad_list = 30*[False]\n",
    "bad_list[0:5] = 5*[True]\n",
    "max_turns = 400\n",
    "\n",
    "print (f'sequential score {play_sequential_game(N, clist, vlist, bad_list, max_turns)}')\n",
    "print (f'omniscent score {play_omniscent_game(N, clist, vlist, bad_list, max_turns)}')\n",
    "#print (f'exploring score {play_exploring_game(N, clist, vlist, bad_list, max_turns)}')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}